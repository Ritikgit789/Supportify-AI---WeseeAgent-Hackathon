{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68167392",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(pdf_path)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Extract content\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m text, tables \u001b[38;5;241m=\u001b[39m extract_text_and_tables(pdf_path)\n\u001b[0;32m     64\u001b[0m links \u001b[38;5;241m=\u001b[39m extract_links(pdf_path)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Store in knowledge base\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36mextract_text_and_tables\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(pdf_path) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf\u001b[38;5;241m.\u001b[39mpages:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# Extract text\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m         page_text \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text()\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m page_text:\n\u001b[0;32m     17\u001b[0m             text\u001b[38;5;241m.\u001b[39mappend(page_text)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:538\u001b[0m, in \u001b[0;36mPage.extract_text\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_textmap(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtuplify_list_kwargs(kwargs))\u001b[38;5;241m.\u001b[39mas_string\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:515\u001b[0m, in \u001b[0;36mPage._get_textmap\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     defaults\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout_height\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight})\n\u001b[0;32m    514\u001b[0m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefaults, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mchars_to_textmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfplumber\\container.py:52\u001b[0m, in \u001b[0;36mContainer.chars\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_obj_list:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:347\u001b[0m, in \u001b[0;36mPage.objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_objects()\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:451\u001b[0m, in \u001b[0;36mPage.parse_objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[0;32m    450\u001b[0m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_layout_objects(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39m_objs):\n\u001b[0;32m    452\u001b[0m         kind \u001b[38;5;241m=\u001b[39m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manno\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfplumber\\page.py:277\u001b[0m, in \u001b[0;36mPage.layout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m device \u001b[38;5;241m=\u001b[39m PDFPageAggregatorWithMarkedContent(\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mrsrcmgr,\n\u001b[0;32m    273\u001b[0m     pageno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_number,\n\u001b[0;32m    274\u001b[0m     laparams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mlaparams,\n\u001b[0;32m    275\u001b[0m )\n\u001b[0;32m    276\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mrsrcmgr, device)\n\u001b[1;32m--> 277\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mprocess_page(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_obj)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout: LTPage \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mget_result()\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:997\u001b[0m, in \u001b[0;36mPDFPageInterpreter.process_page\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    995\u001b[0m     ctm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mx0, \u001b[38;5;241m-\u001b[39my0)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbegin_page(page, ctm)\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_contents(page\u001b[38;5;241m.\u001b[39mresources, page\u001b[38;5;241m.\u001b[39mcontents, ctm\u001b[38;5;241m=\u001b[39mctm)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mend_page(page)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1016\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[1;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_resources(resources)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(ctm)\n\u001b[1;32m-> 1016\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(list_value(streams))\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1027\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[1;34m(self, streams)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1027\u001b[0m         (_, obj) \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mnextobject()\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[0;32m   1029\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfminer\\psparser.py:609\u001b[0m, in \u001b[0;36mPSStackParser.nextobject\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields a list of objects.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03mArrays and dictionaries are represented as Python lists and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m:return: keywords, literals, strings, numbers, arrays and dictionaries.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m--> 609\u001b[0m     (pos, token) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnexttoken()\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, PSLiteral)):\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;66;03m# normal token\u001b[39;00m\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush((pos, token))\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfminer\\psparser.py:527\u001b[0m, in \u001b[0;36mPSBaseParser.nexttoken\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokens:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfillbuf()\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharpos)\n\u001b[0;32m    528\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokens\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    529\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnexttoken: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, token)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pdfminer\\psparser.py:320\u001b[0m, in \u001b[0;36mPSBaseParser._parse_main\u001b[1;34m(self, s, i)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_float\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m c\u001b[38;5;241m.\u001b[39misalpha():\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_curtoken \u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_keyword\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Step 1: Define functions to extract text, tables, and links\n",
    "\n",
    "def extract_text_and_tables(pdf_path):\n",
    "    \"\"\"Extract text and tables from a PDF using pdfplumber.\"\"\"\n",
    "    text = []\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "            # Extract tables\n",
    "            page_tables = page.extract_tables()\n",
    "            for table in page_tables:\n",
    "                # Convert table to list of lists for JSON\n",
    "                tables.append({\n",
    "                    'page': page.page_number,\n",
    "                    'table': table\n",
    "                })\n",
    "    return \"\\n\\n\".join(text), tables\n",
    "\n",
    "def extract_links(pdf_path):\n",
    "    \"\"\"Extract links from a PDF using PyMuPDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    links = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        for link in page.get_links():\n",
    "            # Store link data\n",
    "            links.append({\n",
    "                'page': page_num + 1,\n",
    "                'url': link.get('uri', ''),\n",
    "                'text': link.get('title', '')  # Not always available\n",
    "            })\n",
    "    doc.close()\n",
    "    return links\n",
    "\n",
    "# Step 2: Walk through all folders and collect PDFs\n",
    "\n",
    "base_dir = 'E:/WESEEAGENT/Archibus Docs'  # Change to your main folder\n",
    "pdfs = []\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdfs.append(os.path.join(root, file))\n",
    "\n",
    "# Step 3: Process all PDFs and build knowledge base\n",
    "\n",
    "knowledge_base = []\n",
    "\n",
    "for pdf_path in pdfs:\n",
    "    # Get folder and file info\n",
    "    folder = os.path.relpath(os.path.dirname(pdf_path), base_dir)\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    \n",
    "    # Extract content\n",
    "    text, tables = extract_text_and_tables(pdf_path)\n",
    "    links = extract_links(pdf_path)\n",
    "    \n",
    "    # Store in knowledge base\n",
    "    knowledge_base.append({\n",
    "        'folder': folder,\n",
    "        'file': filename,\n",
    "        'text': text,\n",
    "        'tables': tables,\n",
    "        'links': links\n",
    "    })\n",
    "\n",
    "# Step 4: Save knowledge base as JSON\n",
    "\n",
    "with open('knowledge_base.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(knowledge_base, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Knowledge base saved as knowledge_base.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d85f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7ff8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/5429 PDFs\n",
      "Processed 100/5429 PDFs\n",
      "Processed 150/5429 PDFs\n",
      "Processed 200/5429 PDFs\n",
      "Processed 250/5429 PDFs\n",
      "Processed 300/5429 PDFs\n",
      "Processed 350/5429 PDFs\n",
      "Processed 400/5429 PDFs\n",
      "Processed 450/5429 PDFs\n",
      "Processed 500/5429 PDFs\n",
      "Processed 550/5429 PDFs\n",
      "Processed 600/5429 PDFs\n",
      "Processed 650/5429 PDFs\n",
      "Processed 700/5429 PDFs\n",
      "Processed 750/5429 PDFs\n",
      "Processed 800/5429 PDFs\n",
      "Processed 850/5429 PDFs\n",
      "Processed 900/5429 PDFs\n",
      "Processed 950/5429 PDFs\n",
      "Processed 1000/5429 PDFs\n",
      "Processed 1050/5429 PDFs\n",
      "Processed 1100/5429 PDFs\n",
      "Processed 1150/5429 PDFs\n",
      "Processed 1200/5429 PDFs\n",
      "Processed 1250/5429 PDFs\n",
      "Processed 1300/5429 PDFs\n",
      "Processed 1350/5429 PDFs\n",
      "Processed 1400/5429 PDFs\n",
      "Processed 1450/5429 PDFs\n",
      "Processed 1500/5429 PDFs\n",
      "Processed 1550/5429 PDFs\n",
      "Processed 1600/5429 PDFs\n",
      "Processed 1650/5429 PDFs\n",
      "Processed 1700/5429 PDFs\n",
      "Processed 1750/5429 PDFs\n",
      "Processed 1800/5429 PDFs\n",
      "Processed 1850/5429 PDFs\n",
      "Processed 1900/5429 PDFs\n",
      "Processed 1950/5429 PDFs\n",
      "Processed 2000/5429 PDFs\n",
      "Processed 2050/5429 PDFs\n",
      "Processed 2100/5429 PDFs\n",
      "Processed 2150/5429 PDFs\n",
      "Processed 2200/5429 PDFs\n",
      "Processed 2250/5429 PDFs\n",
      "Processed 2300/5429 PDFs\n",
      "Processed 2350/5429 PDFs\n",
      "Processed 2400/5429 PDFs\n",
      "Processed 2450/5429 PDFs\n",
      "Processed 2500/5429 PDFs\n",
      "Processed 2550/5429 PDFs\n",
      "Processed 2600/5429 PDFs\n",
      "Processed 2650/5429 PDFs\n",
      "Processed 2700/5429 PDFs\n",
      "Processed 2750/5429 PDFs\n",
      "Processed 2800/5429 PDFs\n",
      "Processed 2850/5429 PDFs\n",
      "Processed 2900/5429 PDFs\n",
      "Processed 2950/5429 PDFs\n",
      "Processed 3000/5429 PDFs\n",
      "Processed 3050/5429 PDFs\n",
      "Processed 3100/5429 PDFs\n",
      "Processed 3150/5429 PDFs\n",
      "Processed 3200/5429 PDFs\n",
      "Processed 3250/5429 PDFs\n",
      "Processed 3300/5429 PDFs\n",
      "Processed 3350/5429 PDFs\n",
      "Processed 3400/5429 PDFs\n",
      "Processed 3450/5429 PDFs\n",
      "Processed 3500/5429 PDFs\n",
      "Processed 3550/5429 PDFs\n",
      "Processed 3600/5429 PDFs\n",
      "Processed 3650/5429 PDFs\n",
      "Processed 3700/5429 PDFs\n",
      "Processed 3750/5429 PDFs\n",
      "Processed 3800/5429 PDFs\n",
      "Processed 3850/5429 PDFs\n",
      "Processed 3900/5429 PDFs\n",
      "Processed 3950/5429 PDFs\n",
      "Processed 4000/5429 PDFs\n",
      "Processed 4050/5429 PDFs\n",
      "Processed 4100/5429 PDFs\n",
      "Processed 4150/5429 PDFs\n",
      "Processed 4200/5429 PDFs\n",
      "Processed 4250/5429 PDFs\n",
      "Processed 4300/5429 PDFs\n",
      "Processed 4350/5429 PDFs\n",
      "Processed 4400/5429 PDFs\n",
      "Processed 4450/5429 PDFs\n",
      "Processed 4500/5429 PDFs\n",
      "Processed 4550/5429 PDFs\n",
      "Processed 4600/5429 PDFs\n",
      "Processed 4650/5429 PDFs\n",
      "Processed 4700/5429 PDFs\n",
      "Processed 4750/5429 PDFs\n",
      "Processed 4800/5429 PDFs\n",
      "Processed 4850/5429 PDFs\n",
      "Processed 4900/5429 PDFs\n",
      "Processed 4950/5429 PDFs\n",
      "Processed 5000/5429 PDFs\n",
      "Processed 5050/5429 PDFs\n",
      "Processed 5100/5429 PDFs\n",
      "Processed 5150/5429 PDFs\n",
      "Processed 5200/5429 PDFs\n",
      "Processed 5250/5429 PDFs\n",
      "Processed 5300/5429 PDFs\n",
      "Processed 5350/5429 PDFs\n",
      "Processed 5400/5429 PDFs\n",
      "Processed 5429/5429 PDFs\n",
      "Knowledge base saved as knowledge_base.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_pdf(pdf_path, base_dir):\n",
    "    folder = os.path.relpath(os.path.dirname(pdf_path), base_dir)\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\\n\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        text = \"Error: \" + str(e)\n",
    "    return {\n",
    "        'folder': folder,\n",
    "        'file': filename,\n",
    "        'text': text\n",
    "    }\n",
    "\n",
    "base_dir = 'E:/WESEEAGENT/Archibus Docs'  # Change to your path\n",
    "pdfs = []\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdfs.append(os.path.join(root, file))\n",
    "\n",
    "knowledge_base = []\n",
    "batch_size = 50  # Adjust as needed\n",
    "for i in range(0, len(pdfs), batch_size):\n",
    "    batch = pdfs[i:i+batch_size]\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(lambda p: process_pdf(p, base_dir), batch))\n",
    "    knowledge_base.extend(results)\n",
    "    print(f\"Processed {i + len(batch)}/{len(pdfs)} PDFs\")\n",
    "\n",
    "with open('knowledge_base.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(knowledge_base, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Knowledge base saved as knowledge_base.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25ee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/5429 PDFs\n",
      "Processed 100/5429 PDFs\n",
      "Processed 150/5429 PDFs\n",
      "Processed 200/5429 PDFs\n",
      "Processed 250/5429 PDFs\n",
      "Processed 300/5429 PDFs\n",
      "Processed 350/5429 PDFs\n",
      "Processed 400/5429 PDFs\n",
      "Processed 450/5429 PDFs\n",
      "Processed 500/5429 PDFs\n",
      "Processed 550/5429 PDFs\n",
      "Processed 600/5429 PDFs\n",
      "Processed 650/5429 PDFs\n",
      "Processed 700/5429 PDFs\n",
      "Processed 750/5429 PDFs\n",
      "Processed 800/5429 PDFs\n",
      "Processed 850/5429 PDFs\n",
      "Processed 900/5429 PDFs\n",
      "Processed 950/5429 PDFs\n",
      "Processed 1000/5429 PDFs\n",
      "Processed 1050/5429 PDFs\n",
      "Processed 1100/5429 PDFs\n",
      "Processed 1150/5429 PDFs\n",
      "Processed 1200/5429 PDFs\n",
      "Processed 1250/5429 PDFs\n",
      "Processed 1300/5429 PDFs\n",
      "Processed 1350/5429 PDFs\n",
      "Processed 1400/5429 PDFs\n",
      "Processed 1450/5429 PDFs\n",
      "Processed 1500/5429 PDFs\n",
      "Processed 1550/5429 PDFs\n",
      "Processed 1600/5429 PDFs\n",
      "Processed 1650/5429 PDFs\n",
      "Processed 1700/5429 PDFs\n",
      "Processed 1750/5429 PDFs\n",
      "Processed 1800/5429 PDFs\n",
      "Processed 1850/5429 PDFs\n",
      "Processed 1900/5429 PDFs\n",
      "Processed 1950/5429 PDFs\n",
      "Processed 2000/5429 PDFs\n",
      "Processed 2050/5429 PDFs\n",
      "Processed 2100/5429 PDFs\n",
      "Processed 2150/5429 PDFs\n",
      "Processed 2200/5429 PDFs\n",
      "Processed 2250/5429 PDFs\n",
      "Processed 2300/5429 PDFs\n",
      "Processed 2350/5429 PDFs\n",
      "Processed 2400/5429 PDFs\n",
      "Processed 2450/5429 PDFs\n",
      "Processed 2500/5429 PDFs\n",
      "Processed 2550/5429 PDFs\n",
      "Processed 2600/5429 PDFs\n",
      "Processed 2650/5429 PDFs\n",
      "Processed 2700/5429 PDFs\n",
      "Processed 2750/5429 PDFs\n",
      "Processed 2800/5429 PDFs\n",
      "Processed 2850/5429 PDFs\n",
      "Processed 2900/5429 PDFs\n",
      "Processed 2950/5429 PDFs\n",
      "Processed 3000/5429 PDFs\n",
      "Processed 3050/5429 PDFs\n",
      "Processed 3100/5429 PDFs\n",
      "Processed 3150/5429 PDFs\n",
      "Processed 3200/5429 PDFs\n",
      "Processed 3250/5429 PDFs\n",
      "Processed 3300/5429 PDFs\n",
      "Processed 3350/5429 PDFs\n",
      "Processed 3400/5429 PDFs\n",
      "Processed 3450/5429 PDFs\n",
      "Processed 3500/5429 PDFs\n",
      "Processed 3550/5429 PDFs\n",
      "Processed 3600/5429 PDFs\n",
      "Processed 3650/5429 PDFs\n",
      "Processed 3700/5429 PDFs\n",
      "Processed 3750/5429 PDFs\n",
      "Processed 3800/5429 PDFs\n",
      "Processed 3850/5429 PDFs\n",
      "Processed 3900/5429 PDFs\n",
      "Processed 3950/5429 PDFs\n",
      "Processed 4000/5429 PDFs\n",
      "Processed 4050/5429 PDFs\n",
      "Processed 4100/5429 PDFs\n",
      "Processed 4150/5429 PDFs\n",
      "Processed 4200/5429 PDFs\n",
      "Processed 4250/5429 PDFs\n",
      "Processed 4300/5429 PDFs\n",
      "Processed 4350/5429 PDFs\n",
      "Processed 4400/5429 PDFs\n",
      "Processed 4450/5429 PDFs\n",
      "Processed 4500/5429 PDFs\n",
      "Processed 4550/5429 PDFs\n",
      "Processed 4600/5429 PDFs\n",
      "Processed 4650/5429 PDFs\n",
      "Processed 4700/5429 PDFs\n",
      "Processed 4750/5429 PDFs\n",
      "Processed 4800/5429 PDFs\n",
      "Processed 4850/5429 PDFs\n",
      "Processed 4900/5429 PDFs\n",
      "Processed 4950/5429 PDFs\n",
      "Processed 5000/5429 PDFs\n",
      "Processed 5050/5429 PDFs\n",
      "Processed 5100/5429 PDFs\n",
      "Processed 5150/5429 PDFs\n",
      "Processed 5200/5429 PDFs\n",
      "Processed 5250/5429 PDFs\n",
      "Processed 5300/5429 PDFs\n",
      "Processed 5350/5429 PDFs\n",
      "Processed 5400/5429 PDFs\n",
      "Processed 5429/5429 PDFs\n",
      "Knowledge base saved as knowledge_base(new).json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the text splitter (you can tweak chunk size & overlap)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "def process_pdf(pdf_path, base_dir):\n",
    "    folder = os.path.relpath(os.path.dirname(pdf_path), base_dir)\n",
    "    filename = os.path.basename(pdf_path)\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            full_text = \"\\n\\n\".join(\n",
    "                page.extract_text() for page in pdf.pages if page.extract_text()\n",
    "            )\n",
    "            chunks = text_splitter.split_text(full_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        chunks = [\"Error: \" + str(e)]\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            'folder': folder,\n",
    "            'file': filename,\n",
    "            'text': chunk,\n",
    "            'source': filename\n",
    "        }\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "\n",
    "# Set base directory path\n",
    "base_dir = 'E:/WESEEAGENT/Archibus Docs'  # Change to your path\n",
    "pdfs = []\n",
    "\n",
    "# Walk through all PDFs in subdirectories\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdfs.append(os.path.join(root, file))\n",
    "\n",
    "knowledge_base = []\n",
    "batch_size = 50  # Tune depending on system capability\n",
    "\n",
    "for i in range(0, len(pdfs), batch_size):\n",
    "    batch = pdfs[i:i + batch_size]\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        batch_results = list(executor.map(lambda p: process_pdf(p, base_dir), batch))\n",
    "\n",
    "    # Flatten chunks from all PDFs\n",
    "    for doc_chunks in batch_results:\n",
    "        knowledge_base.extend(doc_chunks)\n",
    "\n",
    "    print(f\"Processed {i + len(batch)}/{len(pdfs)} PDFs\")\n",
    "\n",
    "# Save the full knowledge base with smaller, high-quality chunks\n",
    "with open('knowledge_base.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(knowledge_base, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Knowledge base saved as knowledge_base(new).json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ae6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
